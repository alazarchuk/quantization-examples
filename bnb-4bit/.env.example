# Saves about 2 Gb of memory, just enough to fit the Phi3.5 model in a 24 Gb GPU
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

WANDB_PROJECT=bnb-4bit